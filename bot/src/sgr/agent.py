"""
SGR Agent - –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π Deep Research –∞–≥–µ–Ω—Ç.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç sgr-agent-core –Ω–∞–ø—Ä—è–º—É—é –±–µ–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞.
–° –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Langfuse –¥–ª—è observability.
"""
import asyncio
import logging
from dataclasses import dataclass, field
from typing import AsyncIterator, Type, Optional

from openai import AsyncOpenAI
from sgr_agent_core import (
    AgentConfig,
    LLMConfig,
    SearchConfig,
    ExecutionConfig,
    AgentStatesEnum,
    BaseTool,
)
from sgr_agent_core.agents import SGRAgent
from sgr_agent_core.tools import (
    WebSearchTool,
    ExtractPageContentTool,
    GeneratePlanTool,
    ReasoningTool,
    ClarificationTool,
    AdaptPlanTool,
    CreateReportTool,
    FinalAnswerTool,
)

logger = logging.getLogger(__name__)

# Try to import langfuse and openinference
try:
    from langfuse import observe, Langfuse
    LANGFUSE_AVAILABLE = True
    langfuse_client = None  # Will be initialized if enabled
except ImportError:
    LANGFUSE_AVAILABLE = False
    observe = lambda *args, **kwargs: lambda f: f  # no-op decorator
    langfuse_client = None
    Langfuse = None

# Try to import OpenAI instrumentor for detailed LLM tracing
try:
    from openinference.instrumentation.openai import OpenAIInstrumentor
    OPENAI_INSTRUMENTOR_AVAILABLE = True
except ImportError:
    OPENAI_INSTRUMENTOR_AVAILABLE = False
    OpenAIInstrumentor = None


def setup_langfuse(
    public_key: str,
    secret_key: str,
    host: str = "https://cloud.langfuse.com",
) -> bool:
    """
    Setup Langfuse environment variables for tracing.
    Returns True if setup successful.
    """
    global langfuse_client
    try:
        import os
        os.environ["LANGFUSE_PUBLIC_KEY"] = public_key
        os.environ["LANGFUSE_SECRET_KEY"] = secret_key
        os.environ["LANGFUSE_HOST"] = host

        if LANGFUSE_AVAILABLE and Langfuse:
            # Initialize client to ensure connection works
            langfuse_client = Langfuse(
                public_key=public_key,
                secret_key=secret_key,
                host=host,
            )
            logger.info(f"Langfuse configured (host: {host})")

            # Enable OpenAI instrumentation for detailed LLM tracing
            if OPENAI_INSTRUMENTOR_AVAILABLE and OpenAIInstrumentor:
                OpenAIInstrumentor().instrument()
                logger.info("OpenAI instrumentation enabled (OpenInference)")

            return True
        else:
            logger.warning("Langfuse not installed")
            return False
    except Exception as e:
        logger.warning(f"Failed to setup Langfuse: {e}")
        return False


def create_openai_client(api_key: str, base_url: str) -> AsyncOpenAI:
    """Create standard OpenAI client."""
    return AsyncOpenAI(api_key=api_key, base_url=base_url)


@dataclass
class ResearchProgress:
    """–ü—Ä–æ–≥—Ä–µ—Å—Å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é."""

    step: int = 0
    tool_name: str = ""
    tool_emoji: str = ""
    description: str = ""
    searches_done: int = 0
    is_final: bool = False


# –ú–∞–ø–ø–∏–Ω–≥ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —ç–º–æ–¥–∑–∏ –∏ –æ–ø–∏—Å–∞–Ω–∏—è
TOOL_INFO = {
    "generateplantool": ("üìã", "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"),
    "websearchtool": ("üîç", "–ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"),
    "extractpagecontenttool": ("üìÑ", "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"),
    "reasoningtool": ("üß†", "–ê–Ω–∞–ª–∏–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"),
    "clarificationtool": ("‚ùì", "–ó–∞–ø—Ä–æ—Å —É—Ç–æ—á–Ω–µ–Ω–∏—è"),
    "adaptplantool": ("üîÑ", "–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–ª–∞–Ω–∞"),
    "createreporttool": ("üìù", "–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞"),
    "finalanswertool": ("‚úÖ", "–§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞"),
}


def get_tool_info(tool_name: str) -> tuple[str, str]:
    """–ü–æ–ª—É—á–∏—Ç—å —ç–º–æ–¥–∑–∏ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞."""
    key = tool_name.lower().replace("_", "")
    return TOOL_INFO.get(key, ("üîß", tool_name))


@dataclass
class ResearchResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è."""

    content: str = ""
    is_done: bool = False
    needs_clarification: bool = False
    clarification_question: str | None = None
    tools_used: list[str] = field(default_factory=list)
    iterations: int = 0
    error: str | None = None
    progress: ResearchProgress | None = None  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞


class DeepResearchAgent:
    """
    Deep Research –∞–≥–µ–Ω—Ç –Ω–∞ –±–∞–∑–µ SGR Agent Core.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Schema-Guided Reasoning –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
    —Å –ø–æ–∏—Å–∫–æ–º –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —á–µ—Ä–µ–∑ Tavily.
    """

    # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–≥–µ–Ω—Ç–∞
    SYSTEM_PROMPT = (
        "–¢—ã - –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. "
        "–í–°–ï–ì–î–ê –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —è–∑—ã–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. "
        "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç—ã —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏ —Å–ø–∏—Å–∫–∞–º–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —á—Ç–µ–Ω–∏—è."
    )

    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –Ω–∞–±–æ—Ä tools –¥–ª—è deep research (—Å–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Å–æ–≤)
    DEFAULT_TOOLS: list[Type[BaseTool]] = [
        WebSearchTool,
        ExtractPageContentTool,
        GeneratePlanTool,
        ReasoningTool,
        ClarificationTool,
        AdaptPlanTool,
        CreateReportTool,
        FinalAnswerTool,
    ]

    def __init__(
        self,
        anthropic_api_key: str,
        tavily_api_key: str,
        model: str = "claude-haiku-4-5",
        api_base: str = "https://api.anthropic.com/v1",
        temperature: float = 0.4,
        max_tokens: int = 8000,
        max_iterations: int = 10,
        max_searches: int = 4,
        max_clarifications: int = 3,
        # Langfuse settings
        langfuse_enabled: bool = False,
        langfuse_public_key: str = "",
        langfuse_secret_key: str = "",
        langfuse_host: str = "https://cloud.langfuse.com",
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞.

        Args:
            anthropic_api_key: API –∫–ª—é—á Anthropic
            tavily_api_key: API –∫–ª—é—á Tavily –¥–ª—è –≤–µ–±-–ø–æ–∏—Å–∫–∞
            model: –ú–æ–¥–µ–ª—å Claude (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é Haiku 4.5)
            api_base: Base URL API
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            max_iterations: –ú–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π –∞–≥–µ–Ω—Ç–∞
            max_searches: –ú–∞–∫—Å–∏–º—É–º –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            max_clarifications: –ú–∞–∫—Å–∏–º—É–º —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            langfuse_enabled: –í–∫–ª—é—á–∏—Ç—å —Ç—Ä–µ–π—Å–∏–Ω–≥ Langfuse
            langfuse_public_key: –ü—É–±–ª–∏—á–Ω—ã–π –∫–ª—é—á Langfuse
            langfuse_secret_key: –°–µ–∫—Ä–µ—Ç–Ω—ã–π –∫–ª—é—á Langfuse
            langfuse_host: URL —Ö–æ—Å—Ç–∞ Langfuse
        """
        self.anthropic_api_key = anthropic_api_key
        self.tavily_api_key = tavily_api_key
        self.langfuse_enabled = langfuse_enabled

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞
        self.config = AgentConfig(
            llm=LLMConfig(
                api_key=anthropic_api_key,
                model=model,
                base_url=api_base,
                temperature=temperature,
                max_tokens=max_tokens,
            ),
            search=SearchConfig(
                tavily_api_key=tavily_api_key,
                max_searches=max_searches,
                max_results=10,
            ),
            execution=ExecutionConfig(
                max_iterations=max_iterations,
                max_clarifications=max_clarifications,
            ),
        )

        # Setup Langfuse –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        if langfuse_enabled and langfuse_public_key and langfuse_secret_key:
            setup_langfuse(langfuse_public_key, langfuse_secret_key, langfuse_host)

        # OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∫–ª–∏–µ–Ω—Ç
        self.client = create_openai_client(api_key=anthropic_api_key, base_url=api_base)

        # Toolkit - —Å–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Å–æ–≤ tools
        self.toolkit = self.DEFAULT_TOOLS

    @observe(name="deep_research")
    async def research(
        self,
        messages: list[dict],
        user_id: Optional[str] = None,
        session_id: Optional[str] = None,
    ) -> AsyncIterator[ResearchResult]:
        """
        –ü—Ä–æ–≤–µ—Å—Ç–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ –∑–∞–ø—Ä–æ—Å—É —Å —É—á—ë—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.

        Args:
            messages: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI [{"role": "user/assistant", "content": "..."}]
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Ç—Ä–µ–π—Å–∏–Ω–≥–∞ (–¥–ª—è Langfuse)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è —Ç—Ä–µ–π—Å–∏–Ω–≥–∞ (–¥–ª—è Langfuse)

        Yields:
            ResearchResult —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        """
        tools_used: list[str] = []

        # Get last user message for logging
        last_query = messages[-1]["content"] if messages else ""

        # Log Langfuse context info
        if self.langfuse_enabled and LANGFUSE_AVAILABLE:
            logger.debug(f"Langfuse tracing active for query: {last_query[:50]}...")

        try:
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–æ
            messages_with_system = [
                {"role": "system", "content": self.SYSTEM_PROMPT},
                *messages,
            ]

            # –°–æ–∑–¥–∞—ë–º –∞–≥–µ–Ω—Ç–∞ —Å –ø–æ–ª–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            agent = SGRAgent(
                task_messages=messages_with_system,
                openai_client=self.client,
                agent_config=self.config,
                toolkit=self.toolkit,
            )

            # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            logger.info(f"Starting research ({len(messages)} messages): {last_query[:200]}...")

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–≥–µ–Ω—Ç–∞ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
            context = agent._context
            execute_task = asyncio.create_task(agent.execute())

            # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª—è yield –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            last_iteration = 0
            last_tool = ""

            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–∫–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
            while not execute_task.done():
                await asyncio.sleep(0.3)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ –∂–¥—ë—Ç –ª–∏ –∞–≥–µ–Ω—Ç clarification
                if context.state == AgentStatesEnum.WAITING_FOR_CLARIFICATION:
                    logger.info("Agent waiting for clarification, cancelling execute task")
                    execute_task.cancel()
                    try:
                        await execute_task
                    except asyncio.CancelledError:
                        pass
                    break

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ —à–∞–≥ –∏–ª–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
                current_iteration = context.iteration
                current_tool = ""
                tool_detail = ""

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ
                if hasattr(context, 'current_step_reasoning') and context.current_step_reasoning:
                    reasoning = context.current_step_reasoning
                    # –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –≤ function.tool_name_discriminator
                    if hasattr(reasoning, 'function') and reasoning.function:
                        func = reasoning.function
                        if hasattr(func, 'tool_name_discriminator'):
                            current_tool = func.tool_name_discriminator
                        elif hasattr(func, 'tool_name'):
                            current_tool = func.tool_name
                        # –î–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º query
                        if hasattr(func, 'query') and func.query:
                            tool_detail = func.query[:50] + "..." if len(func.query) > 50 else func.query
                        # –î–ª—è –ø–ª–∞–Ω–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ü–µ–ª—å
                        elif hasattr(func, 'research_goal') and func.research_goal:
                            tool_detail = func.research_goal[:50] + "..." if len(func.research_goal) > 50 else func.research_goal
                        # –î–ª—è –æ—Ç—á—ë—Ç–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º title
                        elif hasattr(func, 'title') and func.title:
                            tool_detail = func.title[:50] + "..." if len(func.title) > 50 else func.title

                # Yield –ø—Ä–æ–≥—Ä–µ—Å—Å –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å
                if current_iteration != last_iteration or current_tool != last_tool:
                    if current_tool:
                        emoji, description = get_tool_info(current_tool)
                        if tool_detail:
                            description = f"{description}: {tool_detail}"

                        progress = ResearchProgress(
                            step=current_iteration,
                            tool_name=current_tool,
                            tool_emoji=emoji,
                            description=description,
                            searches_done=context.searches_used,
                            is_final=False,
                        )
                        logger.info(f"Yielding progress: step={current_iteration}, tool={current_tool}, detail={tool_detail[:30] if tool_detail else 'none'}")
                        yield ResearchResult(progress=progress)

                        last_iteration = current_iteration
                        last_tool = current_tool

            # Debug logging
            logger.info(f"Agent state: {context.state}")
            logger.info(f"Execution result: {context.execution_result[:200] if context.execution_result else 'None'}...")
            if hasattr(context, 'current_step_reasoning'):
                logger.info(f"Current step reasoning: {context.current_step_reasoning}")
            if hasattr(context, 'clarification_received'):
                logger.info(f"Clarification received: {context.clarification_received}")

            # –°–æ–±–∏—Ä–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ tools
            if hasattr(context, 'tools_called'):
                tools_used = list(context.tools_called)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫—É
            if context.state == AgentStatesEnum.FAILED:
                error_msg = context.execution_result or "–ê–≥–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π"
                logger.error(f"Agent failed: {error_msg}")
                yield ResearchResult(
                    is_done=True,
                    error=error_msg,
                    tools_used=tools_used,
                    iterations=context.iteration if hasattr(context, 'iteration') else 0,
                )
                return

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ —É—Ç–æ—á–Ω–µ–Ω–∏–µ
            if context.state == AgentStatesEnum.WAITING_FOR_CLARIFICATION:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–æ–ø—Ä–æ—Å—ã –∏–∑ current_step_reasoning.function.questions
                clarification_questions = None
                if hasattr(context, 'current_step_reasoning') and context.current_step_reasoning:
                    reasoning = context.current_step_reasoning
                    if hasattr(reasoning, 'function') and reasoning.function:
                        func = reasoning.function
                        if hasattr(func, 'questions') and func.questions:
                            clarification_questions = "\n".join(func.questions)

                logger.info(f"Clarification questions extracted: {clarification_questions}")

                yield ResearchResult(
                    needs_clarification=True,
                    clarification_question=clarification_questions or "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å.",
                    tools_used=tools_used,
                    iterations=context.iteration if hasattr(context, 'iteration') else 0,
                )
                return

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result_content = context.execution_result or ""
            iterations = context.iteration if hasattr(context, 'iteration') else 0

            yield ResearchResult(
                content=result_content,
                is_done=True,
                tools_used=tools_used,
                iterations=iterations,
            )

            logger.info(f"Research completed. Tools used: {tools_used}")

            # Flush Langfuse traces
            if self.langfuse_enabled and LANGFUSE_AVAILABLE and langfuse_client:
                try:
                    langfuse_client.flush()
                    logger.debug("Langfuse traces flushed")
                except Exception as flush_err:
                    logger.debug(f"Failed to flush Langfuse: {flush_err}")

        except Exception as e:
            logger.error(f"Research failed: {e}")
            yield ResearchResult(
                is_done=True,
                error=str(e),
                tools_used=tools_used,
            )



def create_agent_from_config(config) -> DeepResearchAgent:
    """
    –°–æ–∑–¥–∞—Ç—å –∞–≥–µ–Ω—Ç–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –±–æ—Ç–∞.

    Args:
        config: Config –æ–±—ä–µ–∫—Ç —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏

    Returns:
        DeepResearchAgent –∏–Ω—Å—Ç–∞–Ω—Å
    """
    return DeepResearchAgent(
        anthropic_api_key=config.llm_api_key,
        tavily_api_key=config.tavily_api_key,
        model=config.llm_model,
        api_base=config.llm_api_base,
        temperature=config.llm_temperature,
        max_tokens=config.llm_max_tokens,
        max_iterations=config.sgr_max_iterations,
        max_searches=config.max_searches,
        max_clarifications=config.sgr_max_clarifications,
        langfuse_enabled=config.langfuse_enabled,
        langfuse_public_key=config.langfuse_public_key,
        langfuse_secret_key=config.langfuse_secret_key,
        langfuse_host=config.langfuse_host,
    )
